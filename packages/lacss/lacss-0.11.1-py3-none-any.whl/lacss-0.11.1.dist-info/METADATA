Metadata-Version: 2.1
Name: lacss
Version: 0.11.1
Summary: Tools for cell segmentation
License: MIT
Author: Ji Yu
Author-email: jyu@uchc.edu
Requires-Python: >=3.10,<4.0
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: imagecodecs (>=2023.3.16,<2024.0.0)
Requires-Dist: imageio (>=2.9.0,<3.0.0)
Requires-Dist: lap (>=0.4.0,<0.5.0)
Requires-Dist: matplotlib (>=3.8.4,<4.0.0)
Requires-Dist: ml-collections (>=0.1.1,<0.2.0)
Requires-Dist: opencv-python (>=4.8.1.78,<5.0.0.0)
Requires-Dist: scikit-image (>=0.19.0)
Requires-Dist: tensorflow (>=2.16.1,<3.0.0)
Requires-Dist: tqdm (>=4.65.0,<5.0.0)
Requires-Dist: typer (>=0.12.3,<0.13.0)
Requires-Dist: xtrain[cuda12] (>=0.3.7,<0.4.0)
Description-Content-Type: text/markdown

## LACSS

_LACSS is a deep-learning model for single-cell segmentation from microscopy images._ 

References: 

- [IEEE TMI doi:10.1109/TMI.2023.3312988](https://ieeexplore.ieee.org/document/10243149)
- [Communications Biology 6,232 (2023)](https://www.nature.com/articles/s42003-023-04608-5)

### What's new (0.11)

#### GRPC server

Lacss now comes with a GRPC server:
```
python -m lacss.deploy.remote_server --modelpath=<model_file_path>
```
For a GUI client see the [Trackmate-Lacss](https://github.com/jiyuuchc/TrackMate-Lacss) project, which provides a FIJI/ImageJ plugin to perform cell segmentation/tracking in a interactive manner.

### Installation
```
pip install lacss
```
For more details, see [documentation](https://jiyuuchc.github.io/lacss/install/)

### Why LACSS?
LACSS is designed to utilize point labels for model training. You have three options:

| Method | Data(left) / Label(right)|
| --- | --- |
| Point | <img src="https://github.com/jiyuuchc/lacss/raw/main-jax/.github/images/label_scheme_1.png" width="300"> |
| Point + Mask | <img src="https://github.com/jiyuuchc/lacss/raw/main-jax/.github/images/label_scheme_2.png" width="300"> |
| Segmentation | <img src="https://github.com/jiyuuchc/lacss/raw/main-jax/.github/images/label_scheme_3.png" width="300"> |

You can of course also combined these labels in any way you want.

### What is included?

- A library for training LACSS model and performing inference
- A few pretrained models as transfer learning starting point
- SMC-based cell tracking utility for people interested in cell tracking

### How to generate point label?

If your data include nuclei counter-stain, the easist way to generate point label for your image is to use a [blob detection](https://scikit-image.org/docs/stable/auto_examples/features_detection/plot_blob.html) algorithm on the nuclei images:

![](https://github.com/jiyuuchc/lacss/raw/main-jax/.github/images/blob_detection.png)

### Give it a try:
* Model training
  * [Supervised Training ![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jiyuuchc/lacss/blob/main-jax/notebooks/train_with_segmentation_label.ipynb)
  * [With point label + mask ![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jiyuuchc/lacss/blob/main-jax/notebooks/train_with_point_and_mask.ipynb)
  * [With point label only ![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jiyuuchc/lacss/blob/main-jax/notebooks/train_with_point_label.ipynb)

* [Inference ![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jiyuuchc/lacss/blob/main-jax/notebooks/inference.ipynb)

### Documentation
  [API documentation](https://jiyuuchc.github.io/lacss/api/deploy/)

