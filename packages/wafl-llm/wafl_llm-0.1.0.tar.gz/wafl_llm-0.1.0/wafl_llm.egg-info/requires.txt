vllm==0.4.2
flash-attn==2.5.8
transformers==4.41.0
sentencepiece==0.1.98
accelerate==0.28.0
bitsandbytes==0.41.3
optimum==1.8.6
onnx==1.13.0
datasets==2.8.0
mpi4py==3.1.4
torchserve==0.7.1
torch-model-archiver==0.7.1
torch-workflow-archiver==0.2.6
nvgpu==0.9.0
fairseq==0.12.2
g2p_en==2.1.0
sentence_transformers==2.7.0
einops==0.6.1
