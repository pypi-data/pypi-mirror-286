gai_url: ""
logging:
    level: "INFO"
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
    datefmt: "%Y-%m-%d %H:%M:%S"
    filename: ""
    filemode: "a"
    stream: "stdout"
    loggers:
        gai.lib.ttt: "DEBUG"
        gai_common.http_utils: "DEBUG"
generators:
    ttt-gai:
        type: ttt
        url: "http://localhost:12031/gen/v1/chat/completions"
        whitelist:
            - temperature
            - top_p
            - min_p
            - top_k
            - max_new_tokens
            - typical
            - n
            - token_repetition_penalty_max
            - token_repetition_penalty_sustain
            - token_repetition_penalty_decay
            - beams
            - beam_length
        env:
            gai_api_key: "gai_api_key"

    ttt-openai:
        type: ttt
        whitelist:
            - max_tokens
            - temperature
            - top_p
            - presence_penalty
            - frequency_penalty
            - stop
            - logit_bias
            - n
            - stream
            - openai_api_key
        default:
            temperature: 1.2
            top_p: 0.15
            top_k: 50
            max_tokens: 1000
        env:
            OPENAI_API_KEY: "OPENAI_API_KEY"

    ttt-long-gai:
        type: ttt
        url: "http://localhost:12031/gen/v1/longchat/completions"
        whitelist:
            - temperature
            - top_p
            - min_p
            - top_k
            - max_new_tokens
            - typical
            - n
            - token_repetition_penalty_max
            - token_repetition_penalty_sustain
            - token_repetition_penalty_decay
            - beams
            - beam_length
        default:
            temperature: 1.2
            top_p: 0.15
            min_p: 0.0
            top_k: 50
            max_new_tokens: 1000
            typical: 0.0
            token_repetition_penalty_max: 1.25
            token_repetition_penalty_sustain: 256
            token_repetition_penalty_decay: 128
            beams: 1
            beam_length: 1
        env:
            gai_api_key: "gai_api_key"

    ttt-long-claude:
        type: ttt
        whitelist:
            - max_tokens_to_sample
            - temperature
            - top_p
            - top_k
            - stop_sequences
        default:
            temperature: 1.2
            top_p: 0.15
            top_k: 50
            max_tokens_to_sample: 1000
        env:
            ANTHROPIC_API_KEY: "ANTHROPIC_API_KEY"

    tts-gai:
        type: tts
        url: "http://localhost:12032/gen/v1/audio/speech"
        env:
            gai_api_key: "gai_api_key"
    tts-openai:
        type: tts
        env:
            OPENAI_API_KEY: "OPENAI_API_KEY"

    stt-gai:
        type: stt
        url: "http://localhost:12033/gen/v1/audio/transcriptions"
        env:
            gai_api_key: "gai_api_key"
    stt-openai:
        type: stt
        env:
            OPENAI_API_KEY: "OPENAI_API_KEY"

    itt-gai:
        type: itt
        url: "http://localhost:12034/gen/v1/vision/completions"
        env:
            gai_api_key: "gai_api_key"

    itt-openai:
        type: itt
        env:
            OPENAI_API_KEY: "OPENAI_API_KEY"

    tti-openai:
        type: tti
        env:
            OPENAI_API_KEY: "OPENAI_API_KEY"

    tti-gai:
        type: tti
        url: "http://localhost:12035/sdapi/v1/txt2img"
        env:
            gai_api_key: "gai_api_key"

    rag-gai:
        type: rag
        url: http://localhost:12036/gen/v1/rag
        ws_url: ws://localhost:12036/gen/v1/rag/index-file/ws
        env:
            gai_api_key: "gai_api_key"
