# BatchLLM
A framework designed for llm offline distributed inference.
